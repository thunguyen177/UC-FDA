{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpZsXW3dl8_a"
   },
   "source": [
    "# Importing packages and function definition \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1368,
     "status": "ok",
     "timestamp": 1633439242473,
     "user": {
      "displayName": "Thu Nguyễn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64",
      "userId": "04714273295929622355"
     },
     "user_tz": -120
    },
    "id": "s4VrJ8Qc2o9G"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.covariance import OAS\n",
    "from scipy.stats import bartlett\n",
    "\n",
    "def fold_k(X,y,k,G, func):\n",
    "    fold = np.random.choice(np.arange(5), len(y))\n",
    "    Xtrain, ytrain = X[fold != k, :], y[fold != k]\n",
    "    Xtest, ytest = X[fold == k, :], y[fold == k]\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(Xtrain)\n",
    "    Xtrain = scaler.transform(Xtrain)\n",
    "    Xtest = scaler.transform(Xtest)\n",
    "    return func(Xtrain, ytrain, Xtest, ytest, G)\n",
    "\n",
    "def dist(u,v,T):\n",
    "  distance = np.dot((u - v).flatten(), np.matmul(u-v, np.linalg.inv(T)).flatten())\n",
    "  return distance\n",
    "\n",
    "def tradi_lda(X,y, Xtest, ytest, G):\n",
    "  # le2 = LabelEncoder()\n",
    "  # y = le2.fit_transform(y)\n",
    "  W = np.array([sum(y==g)*np.cov(X[y==g,:].T) for g in range(G)])\n",
    "  W = np.sum(W, axis=0)\n",
    "  xbar = np.mean(X, axis = 0) \n",
    "  xi_bar = np.array([np.mean(X[y==g,:], axis=0) for g in range(G)])\n",
    "  B = np.array([sum(y==g)*np.outer(xi_bar[g,:]-xbar,xi_bar[g,:]-xbar.T) for g in range(G)])\n",
    "  B = np.sum(B, axis = 0)\n",
    "  eig_vals, eig_vecs = np.linalg.eig(np.linalg.inv(W).dot(B))\n",
    "  eig_vecs = np.real(eig_vecs)\n",
    "\n",
    "  # prediction\n",
    "  n_take = sum(np.abs(np.real(eig_vals)) >0.000001)# number of eigvalues chosen  \n",
    "  f = lambda x, k: sum(np.array([(eig_vecs[:,r].dot(x - xi_bar[k,:]))**2 for r in range(n_take)]))\n",
    "  score = lambda i: np.array([f(Xtest[i,:],k) for k in range(G)])\n",
    "  ypred = np.array([np.argmin(score(i)) for i in range(len(ytest))])  \n",
    "  # ypred = le2.inverse_transform(ypred)\n",
    "  return sum(ypred !=ytest)/len(ytest)#confusion_matrix(ytest, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1633439242476,
     "user": {
      "displayName": "Thu Nguyễn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64",
      "userId": "04714273295929622355"
     },
     "user_tz": -120
    },
    "id": "OM9uUOPoHKE2"
   },
   "outputs": [],
   "source": [
    "def shrink_lda(X,y, Xtest, ytest, G):\n",
    "  le2 = LabelEncoder()\n",
    "  y = le2.fit_transform(y)\n",
    "  W = np.array([sum(y==g)*OAS().fit(X[y==g,:]).covariance_ for g in range(G)])\n",
    "  W = np.sum(W, axis=0)\n",
    "  xbar = np.mean(X, axis = 0) \n",
    "  xi_bar = np.array([np.mean(X[y==g,:], axis=0) for g in range(G)])\n",
    "  B = np.array([sum(y==g)*np.outer(xi_bar[g,:]-xbar,xi_bar[g,:]-xbar.T) for g in range(G)])\n",
    "  B = np.sum(B, axis = 0)\n",
    "  eig_vals, eig_vecs = np.linalg.eig(np.linalg.inv(W).dot(B))\n",
    "  eig_vecs = np.real(eig_vecs)\n",
    "\n",
    "  # prediction\n",
    "  n_take = sum(np.abs(np.real(eig_vals)) >0.000001)\n",
    "  f = lambda x, k: sum(np.array([(eig_vecs[:,r].dot(x - xi_bar[k,:]))**2 for r in range(n_take)]))\n",
    "  score = lambda i: np.array([f(Xtest[i,:],k) for k in range(G)])\n",
    "  ypred = np.array([np.argmin(score(i)) for i in range(len(ytest))])  \n",
    "  ypred = le2.inverse_transform(ypred)\n",
    "  return sum(ypred !=ytest)/len(ytest)#confusion_matrix(ytest, ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Kdb4MYtJ52Q"
   },
   "source": [
    "# VarLDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1633439242478,
     "user": {
      "displayName": "Thu Nguyễn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64",
      "userId": "04714273295929622355"
     },
     "user_tz": -120
    },
    "id": "ZTnGP3TL7pLo"
   },
   "outputs": [],
   "source": [
    "def varLDA(X,y,Xtest,ytest,G):\n",
    "  W = np.array([sum(y==g)*np.cov(X[y==g,:].T) for g in range(G)])\n",
    "  W = np.sum(W, axis=0)\n",
    "  xbar = np.mean(X, axis = 0) \n",
    "  xi_bar = np.array([np.mean(X[y==g,:], axis=0) for g in range(G)])\n",
    "  B = np.array([sum(y==g)*np.outer(xi_bar[g,:]-xbar,xi_bar[g,:]-xbar.T) for g in range(G)])\n",
    "  B = np.sum(B, axis = 0)\n",
    "  eig_vals, eig_vecs = np.linalg.eig(np.linalg.inv(W).dot(B))\n",
    "  eig_vecs = np.real(eig_vecs)\n",
    "\n",
    "  n_take = sum(np.abs(np.real(eig_vals)) >0.000001)\n",
    "  # compute class variances in transformed space\n",
    "  space_i_var = lambda i:  np.array([eig_vecs[:,i].dot(\n",
    "      np.matmul(np.cov(X[y==g,:].T),eig_vecs[:,i].T)) for g in range(G)])\n",
    "  vars = np.array([space_i_var(i) for i in range(n_take)])\n",
    "  # print('vars:\\n', vars)\n",
    "\n",
    "  # prediction\n",
    "  f = lambda x, k: sum(np.array([(eig_vecs[:,r].dot(x - xi_bar[k,:]))**2/vars[r,k] for r in range(n_take)]))\n",
    "  score = lambda i: np.array([f(Xtest[i,:],k) for k in range(G)])\n",
    "  ypred = np.array([np.argmin(score(i)) for i in range(len(ytest))])  \n",
    "  return sum(ypred !=ytest)/len(ytest)#confusion_matrix(ytest, ypred)  \n",
    "\n",
    "def qda(Xtrain, ytrain, Xtest, ytest, G):\n",
    "  clf = QuadraticDiscriminantAnalysis()\n",
    "  clf.fit(Xtrain, ytrain)\n",
    "  return sum(clf.predict(Xtest)!=ytest)/len(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1633439242830,
     "user": {
      "displayName": "Thu Nguyễn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64",
      "userId": "04714273295929622355"
     },
     "user_tz": -120
    },
    "id": "Cc0IjKjLF3RY"
   },
   "outputs": [],
   "source": [
    "def varShrinkLDA(X,y,Xtest,ytest,G):\n",
    "  le2 = LabelEncoder()\n",
    "  y = le2.fit_transform(y)  \n",
    "  W = np.array([sum(y==g)*OAS().fit(X[y==g,:]).covariance_ for g in range(G)])\n",
    "  W = np.sum(W, axis=0)\n",
    "  xbar = np.mean(X, axis = 0) \n",
    "  xi_bar = np.array([np.mean(X[y==g,:], axis=0) for g in range(G)])\n",
    "  B = np.array([sum(y==g)*np.outer(xi_bar[g,:]-xbar,xi_bar[g,:]-xbar.T) for g in range(G)])\n",
    "  B = np.sum(B, axis = 0)\n",
    "  eig_vals, eig_vecs = np.linalg.eig(np.linalg.inv(W).dot(B))\n",
    "  eig_vecs = np.real(eig_vecs)\n",
    "\n",
    "  n_take = sum(np.abs(np.real(eig_vals)) >0.000001)\n",
    "  # compute class variances in transformed space\n",
    "  space_i_var = lambda i:  np.array([eig_vecs[:,i].dot(\n",
    "      np.matmul(np.cov(X[y==g,:].T),eig_vecs[:,i].T)) for g in range(G)])\n",
    "  vars = np.array([space_i_var(i) for i in range(n_take)])\n",
    "  # print('vars:\\n', vars)\n",
    "\n",
    "  # # prediction\n",
    "  f = lambda x, k: sum(np.array([(eig_vecs[:,r].dot(x - xi_bar[k,:]))**2/vars[r,k] for r in range(n_take)]))\n",
    "  score = lambda i: np.array([f(Xtest[i,:],k) for k in range(G)])\n",
    "  ypred = np.array([np.argmin(score(i)) for i in range(len(ytest))])  \n",
    "  ypred = le2.inverse_transform(ypred)\n",
    "  return sum(ypred !=ytest)/len(ytest)#confusion_matrix(ytest, ypred)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fs_p7TooaI_B"
   },
   "source": [
    "# Lp LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1633439253047,
     "user": {
      "displayName": "Thu Nguyễn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64",
      "userId": "04714273295929622355"
     },
     "user_tz": -120
    },
    "id": "2UtmvyUvaLrk"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "#Based on the paper \"Generalization of linear discriminant analysis using Lp-norm\" by J.H.Oh and N.Kwak\n",
    "def sign_function(a):\n",
    "    if (a>0):\n",
    "       return 1\n",
    "    elif (a==0):\n",
    "       return 0\n",
    "    else:\n",
    "       return -1\n",
    "\n",
    "def singularity_condition(X,y,w_t,m,m_c):\n",
    "    #The output is 1 (i.e True) if: w(t).T*(m_c-m) = 0 \n",
    "    #or w(t).T*(x_i-m_c_i) = 0 for some x_i\n",
    "    for i in range(len(X)):\n",
    "        if ((np.dot(w_t,(X[i]-m_c[y[i]]))==0) or (np.dot(w_t, (m_c[y[i]] - m))==0)): \n",
    "           return 1\n",
    "    return 0\n",
    "\n",
    "def get_gradient(p,X,y,w_t,m,m_c,G):\n",
    "   \n",
    "    A = np.array([sum(y==g)*sign_function(np.dot(w_t,(m_c[g]-m)))*abs(np.dot(w_t,(m_c[g]-m)))**(p-1)*(m_c[g]-m) for g in range(G)])\n",
    "    A = p*np.sum(A, axis=0)\n",
    "    \n",
    "    B = np.array([(sign_function(np.dot(w_t,(X[i]-m_c[y[i]])))*np.dot(w_t,(X[i]-m_c[y[i]])))**p for i in range(len(X))])\n",
    "    B = np.sum(B,axis=0)\n",
    "\n",
    "    C = np.array([sum(y==g)*(sign_function(np.dot(w_t,(m_c[g]-m)))*np.dot(w_t,(m_c[g]-m)))**p for g in range(G)])\n",
    "    C = np.sum(C,axis=0)\n",
    "\n",
    "    D = np.array([sign_function(np.dot(w_t,(X[i]-m_c[y[i]])))*abs(np.dot(w_t,(X[i]-m_c[y[i]])))**(p-1)*(X[i]-m_c[y[i]]) for i in range(len(X))])\n",
    "    D = p*np.sum(D,axis=0)\n",
    "\n",
    "    E = np.array([(sign_function(np.dot(w_t,(X[i]-m_c[y[i]])))*np.dot(w_t,(X[i]-m_c[y[i]])))**p for i in range(len(X))])\n",
    "    E = (np.sum(E,axis=0))**2\n",
    "\n",
    "    return (A*B - C*D)/E\n",
    "       \n",
    "\n",
    "def lda_lp_one_vector(X, y, G, p, learning_rate, epsilon):\n",
    "    le2 = LabelEncoder()\n",
    "    y = le2.fit_transform(y)\n",
    "    alpha = learning_rate\n",
    "\n",
    "    #Initialization\n",
    "    t=0\n",
    "    N, D = np.shape(X) \n",
    "    w_t = [random.uniform(0.1,0.5) for _ in range(D)] #set an abitrary vector w_t such that ||w_t||_2 = 1\n",
    "    w_t = w_t/np.linalg.norm(w_t)        \n",
    "    \n",
    "    m = np.mean(X, axis = 0)\n",
    "    m_c = np.array([np.mean(X[y==g,:], axis=0) for g in range(G)])\n",
    "\n",
    "    while True:\n",
    "\n",
    "          if (p<=1):\n",
    "             #Singularity check\n",
    "             if (singularity_condition(X,y,w_t,m,m_c)==1): \n",
    "                 #w_t <- w_t + delta/||w_t + delta|| for delta is a small random vector\n",
    "                 n_del = D #(= len(w_t))\n",
    "                 delta = [random.uniform(1e-6,1e-5) for _ in range(n_del)]\n",
    "                 w_t = (w_t + delta)/np.linalg.norm(w_t + delta)\n",
    "\n",
    "          dw = get_gradient(p,X,y,w_t,m,m_c,G)\n",
    "\n",
    "          w_t_0 = w_t       \n",
    "          w_t = w_t + alpha*dw #or \"-\" ??\n",
    "          w_t = w_t/np.linalg.norm(w_t)\n",
    "          if (np.linalg.norm(w_t - w_t_0)<epsilon): break\n",
    "\n",
    "    return w_t      \n",
    "\n",
    "def lda_lp_multiple_vectors(X, y, G, p, learning_rate, epsilon, number_of_vect):\n",
    "    w_j = 0.0\n",
    "    X_j = X\n",
    "    w = []\n",
    "    for j in range(number_of_vect):\n",
    "        for i in range(len(X)):\n",
    "            X_j[i] = X_j[i] - w_j*np.dot(w_j,X_j[i])\n",
    "        w_j =  lda_lp_one_vector(X_j, y, G, p, learning_rate, epsilon)\n",
    "        w.append(w_j)\n",
    "    return np.array(w)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_lp_original(X, y, Xtest, ytest, G, p=1.5,number_of_vect = 1, learning_rate = 0.0001, epsilon=1e-5): #1e-6\n",
    "  n_take = number_of_vect #(i.e Number of projection vectors)\n",
    "  w = lda_lp_multiple_vectors(X,y,G,p,learning_rate,epsilon,number_of_vect)\n",
    "  m = np.mean(X, axis = 0)\n",
    "  m_c = np.array([np.mean(X[y==g,:], axis=0) for g in range(G)])\n",
    "\n",
    "  n_take = number_of_vect\n",
    "  f = lambda x, k: sum(np.array([(w[r,:].dot(x - m_c[k,:]))**2 for r in range(n_take)]))\n",
    "  score = lambda i: np.array([f(Xtest[i,:],k) for k in range(G)])\n",
    "  ypred = np.array([np.argmin(score(i)) for i in range(len(ytest))])  \n",
    "  #ypred = le2.inverse_transform(ypred)\n",
    "  return sum(ypred !=ytest)/len(ytest)#confusion_matrix(ytest, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1633439254213,
     "user": {
      "displayName": "Thu Nguyễn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64",
      "userId": "04714273295929622355"
     },
     "user_tz": -120
    },
    "id": "00YvkGGOaOkF"
   },
   "outputs": [],
   "source": [
    "def lda_lp(X, y, Xtest, ytest, G, p=1.5,number_of_vect = 1, learning_rate = 0.0001, epsilon=1e-5): #NOTE: this is UC-lpLDA\n",
    "  n_take = number_of_vect #(i.e Number of projection vectors)\n",
    "  w = lda_lp_multiple_vectors(X,y,G,p,learning_rate,epsilon,number_of_vect)\n",
    "  m = np.mean(X, axis = 0)\n",
    "  m_c = np.array([np.mean(X[y==g,:], axis=0) for g in range(G)])\n",
    "\n",
    "  # compute class variances in transformed space\n",
    "  space_i_var = lambda i:  np.array([w[i,:].dot(\n",
    "      np.matmul(np.cov(X[y==g,:].T),w[i,:].T)) for g in range(G)])\n",
    "  vars = np.array([space_i_var(i) for i in range(n_take)])\n",
    "  sd = np.sqrt(vars)\n",
    "  # print('vars:\\n', vars)\n",
    "\n",
    "  n_take = number_of_vect\n",
    "  f = lambda x, k: sum(np.array([np.abs(w[r,:].dot(x - m_c[k,:]))/sd[r,k] for r in range(n_take)]))\n",
    "  score = lambda i: np.array([f(Xtest[i,:],k) for k in range(G)])\n",
    "  ypred = np.array([np.argmin(score(i)) for i in range(len(ytest))])  \n",
    "  #ypred = le2.inverse_transform(ypred)\n",
    "  return sum(ypred !=ytest)/len(ytest)#confusion_matrix(ytest, ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1gVrZrAkDzj"
   },
   "source": [
    "# heart \n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/SPECTF+Heart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1014,
     "status": "ok",
     "timestamp": 1633439492244,
     "user": {
      "displayName": "Thu Nguyễn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64",
      "userId": "04714273295929622355"
     },
     "user_tz": -120
    },
    "id": "b9B4vjshkVnE",
    "outputId": "831f8b3d-e84e-4cd5-bb97-77ec0f2904e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(267, 44)\n",
      "55\n",
      "212\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_table('https://archive.ics.uci.edu/ml/machine-learning-databases/spect/SPECTF.train', header = None,sep=',')\n",
    "data.head()\n",
    "test = pd.read_table('https://archive.ics.uci.edu/ml/machine-learning-databases/spect/SPECTF.test',\n",
    "                     header=None, sep = ',')\n",
    "data = pd.concat([data, test])\n",
    "data = data.to_numpy()\n",
    "X,y = data[:,1:], data[:,0]\n",
    "G = len(np.unique(y)) \n",
    "print(np.shape(X))\n",
    "for g in range(G):\n",
    "  print(sum(y==g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "executionInfo": {
     "elapsed": 423,
     "status": "error",
     "timestamp": 1633439494365,
     "user": {
      "displayName": "Thu Nguyễn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64",
      "userId": "04714273295929622355"
     },
     "user_tz": -120
    },
    "id": "9opvdPMKlhHG",
    "outputId": "c2ec4830-1e4f-4f2f-e844-3f9d85c49a73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.34435137042968716, 0.2560807069442864)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "tradi_res = [fold_k(X,y,k,G, tradi_lda) for k in np.arange(5)]\n",
    "varlda_res = [fold_k(X,y,k,G, varLDA) for k in np.arange(5)]\n",
    "b = np.mean(np.asarray(tradi_res), axis=0)\n",
    "c = np.mean(np.asarray(varlda_res), axis=0)\n",
    "b,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 564,
     "status": "ok",
     "timestamp": 1632213202381,
     "user": {
      "displayName": "Thu Nguyễn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64",
      "userId": "04714273295929622355"
     },
     "user_tz": -120
    },
    "id": "6e9yCP0mlkSi",
    "outputId": "d0fa39c0-d4a3-4e19-ecbe-cade80d09b53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2616084671940908 0.3587995741073132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.09719110691322241"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 5\n",
    "varSrhinklda_res = [fold_k(X,y,k,G, varShrinkLDA) for k in np.arange(K)]\n",
    "shrinklda_res = [fold_k(X,y,k,G, shrink_lda) for k in np.arange(K)]\n",
    "print(np.mean(np.asarray(varSrhinklda_res), axis=0), np.mean(np.asarray(shrinklda_res), axis=0))\n",
    "np.mean(np.asarray(varSrhinklda_res), axis=0)- np.mean(np.asarray(shrinklda_res), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2081674351258692"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qda_res = [fold_k(X,y,k,G, qda) for k in np.arange(5)]\n",
    "d = np.mean(np.asarray(qda_res), axis=0)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Vlwg996CfPsn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2724116403220881"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lplda_res = [fold_k(X,y,k,G, lda_lp) for k in np.arange(5)]\n",
    "# print(lplda_res)\n",
    "d = np.mean(np.asarray(lplda_res), axis=0)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3373304334400945"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lplda_res = [fold_k(X,y,k,G, lda_lp_original) for k in np.arange(5)]\n",
    "# print(lplda_res)\n",
    "d = np.mean(np.asarray(lplda_res), axis=0)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LbKYkQlPQN7G"
   },
   "source": [
    "# Car "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "3eFXHaiiQd4P"
   },
   "outputs": [],
   "source": [
    "#source: https://stackoverflow.com/questions/24458645/label-encoding-across-multiple-columns-in-scikit-learn\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "class MultiColumnLabelEncoder:\n",
    "    def __init__(self,columns = None):\n",
    "        self.columns = columns # array of column names to encode\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self # not relevant here\n",
    "\n",
    "    def transform(self,X):\n",
    "        '''\n",
    "        Transforms columns of X specified in self.columns using\n",
    "        LabelEncoder(). If no columns specified, transforms all\n",
    "        columns in X.\n",
    "        '''\n",
    "        output = X.copy()\n",
    "        if self.columns is not None:\n",
    "            for col in self.columns:\n",
    "                output[col] = LabelEncoder().fit_transform(output[col])\n",
    "        else:\n",
    "            for colname,col in output.iteritems():\n",
    "                output[colname] = LabelEncoder().fit_transform(col)\n",
    "        return output\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.fit(X,y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 392,
     "status": "ok",
     "timestamp": 1632166377454,
     "user": {
      "displayName": "Thu Nguyễn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64",
      "userId": "04714273295929622355"
     },
     "user_tz": -120
    },
    "id": "lJY4UhF8QgCS",
    "outputId": "0a71d315-80d3-4c3f-e7c0-03ea0a2362a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['high' 'low' 'med' 'vhigh']\n",
      "['high' 'low' 'med' 'vhigh']\n",
      "['2' '3' '4' '5more']\n",
      "['2' '4' 'more']\n",
      "['big' 'med' 'small']\n",
      "['high' 'low' 'med']\n",
      "   0  1  2  3  4  5  6\n",
      "0  3  3  0  0  2  1  2\n",
      "1  3  3  0  0  2  2  2\n",
      "2  3  3  0  0  2  0  2\n",
      "3  3  3  0  0  1  1  2\n",
      "4  3  3  0  0  1  2  2\n",
      "384\n",
      "69\n",
      "1210\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data',\n",
    "                  sep = \",\", header = None)\n",
    "for i in range(6):\n",
    "  print(np.unique(data[[i]]))\n",
    "data = MultiColumnLabelEncoder(columns = [0,1,2,3,4,5,6]).fit_transform(data)\n",
    "print(data.head())\n",
    "data = data.to_numpy()\n",
    "X,y = data[:, [x for x in range(data.shape[1]) if x != 6]].astype(np.float32),data[:,-1]\n",
    "\n",
    "G = len(np.unique(y))\n",
    "le2 = LabelEncoder()\n",
    "y = le2.fit_transform(y)\n",
    "for g in range(G):\n",
    "  print(sum(y==g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5275899914866666, 0.3964788690978383)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "tradi_res = [fold_k(X,y,k,G, tradi_lda) for k in np.arange(5)]\n",
    "varlda_res = [fold_k(X,y,k,G, varLDA) for k in np.arange(5)]\n",
    "b = np.mean(np.asarray(tradi_res), axis=0)\n",
    "c = np.mean(np.asarray(varlda_res), axis=0)\n",
    "b,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1594,
     "status": "ok",
     "timestamp": 1632166384116,
     "user": {
      "displayName": "Thu Nguyễn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64",
      "userId": "04714273295929622355"
     },
     "user_tz": -120
    },
    "id": "pL9r1vFCLcs-",
    "outputId": "829a659b-170a-4865-feee-b102a17a4c1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.38627138454410814, 0.5014950379507386)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varSrhinklda_res = [fold_k(X,y,k,G, varShrinkLDA) for k in np.arange(K)]\n",
    "shrinklda_res = [fold_k(X,y,k,G, shrink_lda) for k in np.arange(K)]\n",
    "np.mean(np.asarray(varSrhinklda_res), axis=0), np.mean(np.asarray(shrinklda_res), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "priL3R74me0y"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:833: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:833: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:836: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:833: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:833: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:836: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:833: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:833: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:836: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:833: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:833: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:836: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:833: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:833: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:836: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9625860093684422"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qda_res = [fold_k(X,y,k,G, qda) for k in np.arange(5)]\n",
    "d = np.mean(np.asarray(qda_res), axis=0)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "executionInfo": {
     "elapsed": 720769,
     "status": "error",
     "timestamp": 1632180078036,
     "user": {
      "displayName": "Thu Nguyễn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64",
      "userId": "04714273295929622355"
     },
     "user_tz": -120
    },
    "id": "vRmHpQrBsglh",
    "outputId": "62c16cb8-638e-4fb2-96f0-2b75c034653d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48715741265679996"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lplda_res = [fold_k(X,y,k,G, lda_lp) for k in np.arange(5)]\n",
    "# print(lplda_res)\n",
    "d = np.mean(np.asarray(lplda_res), axis=0)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6247749958694064"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lplda_res = [fold_k(X,y,k,G, lda_lp_original) for k in np.arange(5)]\n",
    "# print(lplda_res)\n",
    "d = np.mean(np.asarray(lplda_res), axis=0)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpocryToP-t4"
   },
   "source": [
    "# balance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1031,
     "status": "ok",
     "timestamp": 1633376187176,
     "user": {
      "displayName": "Thu Nguyễn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64",
      "userId": "04714273295929622355"
     },
     "user_tz": -120
    },
    "id": "sP_ArrJvP_Z4",
    "outputId": "a0409a0b-f7fb-4fdc-a5ca-f4b6497a4503"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "288\n",
      "288\n",
      "(625, 4)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/balance-scale/balance-scale.data',\n",
    "                  sep = \",\", header = None)\n",
    "data.head()\n",
    "\n",
    "data = data.to_numpy()\n",
    "X,y = data[:, [x for x in range(data.shape[1]) if x != 0]].astype(np.float32),data[:,0]\n",
    "G = len(np.unique(y))\n",
    "le2 = LabelEncoder()\n",
    "y = le2.fit_transform(y)\n",
    "for g in range(G):\n",
    "  print(sum(y==g))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 485,
     "status": "ok",
     "timestamp": 1632292554944,
     "user": {
      "displayName": "Thu Nguyễn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64",
      "userId": "04714273295929622355"
     },
     "user_tz": -120
    },
    "id": "oBl0vVPH7i7W",
    "outputId": "1862fee1-355d-4e81-cceb-8068c7360912"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2708869839937164, 0.09230761381826066)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "tradi_res = [fold_k(X,y,k,G, tradi_lda) for k in np.arange(5)]\n",
    "varlda_res = [fold_k(X,y,k,G, varLDA) for k in np.arange(5)]\n",
    "a,b = np.mean(np.asarray(tradi_res), axis=0), np.mean(np.asarray(varlda_res), axis=0)\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 600,
     "status": "ok",
     "timestamp": 1632292578329,
     "user": {
      "displayName": "Thu Nguyễn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64",
      "userId": "04714273295929622355"
     },
     "user_tz": -120
    },
    "id": "c023KsS5HsoH",
    "outputId": "8f554891-1c2e-4a5c-f843-61cb8a7a4692"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0839318787427194, 0.25779190323484136)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 5\n",
    "varSrhinklda_res = [fold_k(X,y,k,G, varShrinkLDA) for k in np.arange(K)]\n",
    "shrinklda_res = [fold_k(X,y,k,G, shrink_lda) for k in np.arange(K)]\n",
    "np.mean(np.asarray(varSrhinklda_res), axis=0), np.mean(np.asarray(shrinklda_res), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9RZLx84wmQd8",
    "outputId": "3ec019c6-81be-45f3-8f90-e9c659ec8fff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0839318787427194"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qda_res = [fold_k(X,y,k,G, qda) for k in np.arange(5)]\n",
    "d = np.mean(np.asarray(qda_res), axis=0)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lSQ3I7lDO98e"
   },
   "outputs": [],
   "source": [
    "def fold_k_qda(X,y,k,G):\n",
    "    np.random.seed(1)\n",
    "    fold = np.random.choice(np.arange(5), len(y))\n",
    "    Xtrain, ytrain = X[fold != k, :], y[fold != k]\n",
    "    Xtest, ytest = X[fold == k, :], y[fold == k]\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(Xtrain)\n",
    "    Xtrain = scaler.transform(Xtrain)\n",
    "    Xtest = scaler.transform(Xtest)\n",
    "    cls = Kfda(kernel='sigmoid', n_components=2)\n",
    "    cls.fit(Xtrain, ytrain)\n",
    "    test_score = cls.score(Xtest, ytest)\n",
    "    return 1-test_score #func(Xtrain, ytrain, Xtest, ytest, G)\n",
    "\n",
    "def fold_k_uc_qda(X,y,k,G):\n",
    "    np.random.seed(1)\n",
    "    fold = np.random.choice(np.arange(5), len(y))\n",
    "    Xtrain, ytrain = X[fold != k, :], y[fold != k]\n",
    "    Xtest, ytest = X[fold == k, :], y[fold == k]\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(Xtrain)\n",
    "    Xtrain = scaler.transform(Xtrain)\n",
    "    Xtest = scaler.transform(Xtest)\n",
    "    cls = Kfda(kernel='sigmoid', n_components=2)\n",
    "    cls.fit(Xtrain, ytrain)\n",
    "    ypred = cls.predict_varkda(Xtest)\n",
    "    print(ypred)\n",
    "    return sum(ypred!=ytest)/len(ytest) #func(Xtrain, ytrain, Xtest, ytest, G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 558,
     "status": "ok",
     "timestamp": 1633376283023,
     "user": {
      "displayName": "Thu Nguyễn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64",
      "userId": "04714273295929622355"
     },
     "user_tz": -120
    },
    "id": "6eaI-cTjPuVq",
    "outputId": "c5cbf11c-b544-48c7-9130-a0657c8d5e52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19553763700147783"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kda_res = [fold_k_qda(X,y,k,G) for k in np.arange(5)]\n",
    "# varkda_res = [fold_k_uc_qda(X,y,k,G) for k in np.arange(5)]\n",
    "np.mean(np.asarray(kda_res), axis=0)\n",
    "# np.mean(np.asarray(varkda_res), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "executionInfo": {
     "elapsed": 214,
     "status": "error",
     "timestamp": 1633376317915,
     "user": {
      "displayName": "Thu Nguyễn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64",
      "userId": "04714273295929622355"
     },
     "user_tz": -120
    },
    "id": "I8LrONwn7V6j",
    "outputId": "f59b736b-7948-4a77-fd9c-149c3549933b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22949267426953157"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lplda_res = [fold_k(X,y,k,G, lda_lp) for k in np.arange(5)]\n",
    "# print(lplda_res)\n",
    "d = np.mean(np.asarray(lplda_res), axis=0)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31253305303197737"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lplda_res = [fold_k(X,y,k,G, lda_lp_original) for k in np.arange(5)]\n",
    "# print(lplda_res)\n",
    "d = np.mean(np.asarray(lplda_res), axis=0)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMgYBE33CP6L"
   },
   "source": [
    "# Breast tissue \n",
    "https://archive.ics.uci.edu/ml/datasets/Breast+Tissue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jcMSHIZE9Rpm",
    "outputId": "8a2d1e9c-08ff-4830-f980-6029f4a3345e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Case # Class          I0     PA500       HFS          DA          Area  \\\n",
      "0       1   car  524.794072  0.187448  0.032114  228.800228   6843.598481   \n",
      "1       2   car  330.000000  0.226893  0.265290  121.154201   3163.239472   \n",
      "2       3   car  551.879287  0.232478  0.063530  264.804935  11888.391827   \n",
      "3       4   car  380.000000  0.240855  0.286234  137.640111   5402.171180   \n",
      "4       5   car  362.831266  0.200713  0.244346  124.912559   3290.462446   \n",
      "\n",
      "        A/DA     Max IP          DR           P  \n",
      "0  29.910803  60.204880  220.737212  556.828334  \n",
      "1  26.109202  69.717361   99.084964  400.225776  \n",
      "2  44.894903  77.793297  253.785300  656.769449  \n",
      "3  39.248524  88.758446  105.198568  493.701814  \n",
      "4  26.342127  69.389389  103.866552  424.796503  \n",
      "(106, 9)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel('https://archive.ics.uci.edu/ml/machine-learning-databases/00192/BreastTissue.xls',\n",
    "                     sheet_name=1)\n",
    "print(data.head())\n",
    "data = data.to_numpy()\n",
    "X, y = data[:,2:].astype(np.float32), data[:,1]\n",
    "G = len(np.unique(y))\n",
    "le2 = LabelEncoder()\n",
    "y = le2.fit_transform(y)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.43310343206695345, 0.3821538461538461)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "tradi_res = [fold_k(X,y,k,G, tradi_lda) for k in np.arange(5)]\n",
    "varlda_res = [fold_k(X,y,k,G, varLDA) for k in np.arange(5)]\n",
    "b = np.mean(np.asarray(tradi_res), axis=0)\n",
    "c = np.mean(np.asarray(varlda_res), axis=0)\n",
    "b,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XcC-lQUbID71",
    "outputId": "e835f5a1-b12a-4a8a-fa46-2af41fe65044"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.294113810741688, 0.3686713554987212)"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varSrhinklda_res = [fold_k(X,y,k,G, varShrinkLDA) for k in np.arange(K)]\n",
    "shrinklda_res = [fold_k(X,y,k,G, shrink_lda) for k in np.arange(K)]\n",
    "np.mean(np.asarray(varSrhinklda_res), axis=0), np.mean(np.asarray(shrinklda_res), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7O34HmpHHtYt",
    "outputId": "611e6ce7-2749-43a4-946f-7a13ebe98360"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3878375959079284"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qda_res = [fold_k(X,y,k,G, qda) for k in np.arange(5)]\n",
    "d = np.mean(np.asarray(qda_res), axis=0)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lplda_res = [fold_k(X,y,k,G, lda_lp) for k in np.arange(5)]\n",
    "# print(lplda_res)\n",
    "d = np.mean(np.asarray(lplda_res), axis=0)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5403286445012788"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lplda_res = [fold_k(X,y,k,G, lda_lp_original) for k in np.arange(5)]\n",
    "# print(lplda_res)\n",
    "d = np.mean(np.asarray(lplda_res), axis=0)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxuJMnajbYdb"
   },
   "source": [
    "# Digits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hswv95epberS"
   },
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "X,y = digits.data, digits.target.ravel() \n",
    "#print(X.shape)\n",
    "rmid = np.where(sum(X!=0)<10)\n",
    "X = np.delete(X, rmid,axis = 1)\n",
    "X.shape, sum(y==0)\n",
    "G = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "tradi_res = [fold_k(X,y,k,G, tradi_lda) for k in np.arange(5)]\n",
    "varlda_res = [fold_k(X,y,k,G, varLDA) for k in np.arange(5)]\n",
    "b = np.mean(np.asarray(tradi_res), axis=0)\n",
    "c = np.mean(np.asarray(varlda_res), axis=0)\n",
    "b,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12167676524058242"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qda_res = [fold_k(X,y,k,G, qda) for k in np.arange(5)]\n",
    "d = np.mean(np.asarray(qda_res), axis=0)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Enxu__1qHx4F",
    "outputId": "7930a91d-91d5-44fb-e0f8-519069f15b8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.04928185492370697, 0.04729662971657904)"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varSrhinklda_res = [fold_k(X,y,k,G, varShrinkLDA) for k in np.arange(K)]\n",
    "shrinklda_res = [fold_k(X,y,k,G, shrink_lda) for k in np.arange(K)]\n",
    "np.mean(np.asarray(varSrhinklda_res), axis=0), np.mean(np.asarray(shrinklda_res), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lplda_res = [fold_k(X,y,k,G, lda_lp_original) for k in np.arange(5)]\n",
    "# print(lplda_res)\n",
    "d = np.mean(np.asarray(lplda_res), axis=0)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6301090077636385"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lplda_res = [fold_k(X,y,k,G, lda_lp) for k in np.arange(5)]\n",
    "# print(lplda_res)\n",
    "d = np.mean(np.asarray(lplda_res), axis=0)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UNZ_XlgkcJJ6"
   },
   "source": [
    "# Seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 576,
     "status": "ok",
     "timestamp": 1632248405966,
     "user": {
      "displayName": "Thu Nguyễn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64",
      "userId": "04714273295929622355"
     },
     "user_tz": -120
    },
    "id": "14hlpPqtcL8Z",
    "outputId": "d012fb7d-7955-4ce2-be48-92069d780b42"
   },
   "outputs": [],
   "source": [
    "data = pd.read_table('https://archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt',\n",
    "                     sep = '\\s+', header = None)\n",
    "print(data.head())\n",
    "data = pd.DataFrame.to_numpy(data)\n",
    "# reset the labels to go start from 0  \n",
    "X,y = data[:,:7], data[:,7]-1 \n",
    "y = y.astype(np.int32)\n",
    "G = len(np.unique(y))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "tradi_res = [fold_k(X,y,k,G, tradi_lda) for k in np.arange(5)]\n",
    "varlda_res = [fold_k(X,y,k,G, varLDA) for k in np.arange(5)]\n",
    "b = np.mean(np.asarray(tradi_res), axis=0)\n",
    "c = np.mean(np.asarray(varlda_res), axis=0)\n",
    "b,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1632248411248,
     "user": {
      "displayName": "Thu Nguyễn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64",
      "userId": "04714273295929622355"
     },
     "user_tz": -120
    },
    "id": "ub5mtlJuHEZC",
    "outputId": "eef8758f-ee8e-4f3a-8c72-f37e1beef883"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.03851079826812891, 0.09205473914249165)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varSrhinklda_res = [fold_k(X,y,k,G, varShrinkLDA) for k in np.arange(5)]\n",
    "shrinklda_res = [fold_k(X,y,k,G, shrink_lda) for k in np.arange(5)]\n",
    "np.mean(np.asarray(varSrhinklda_res), axis=0), np.mean(np.asarray(shrinklda_res), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 205,
     "status": "ok",
     "timestamp": 1632248413822,
     "user": {
      "displayName": "Thu Nguyễn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaRl8WgKOjLdrEa69IqFm__Rq7udZ763hhFDl9=s64",
      "userId": "04714273295929622355"
     },
     "user_tz": -120
    },
    "id": "GFAkOO7wHHtW",
    "outputId": "ee80a843-84b1-47a8-b711-49d4a5e598d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05901955727010048"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qda_res = [fold_k(X,y,k,G, qda) for k in np.arange(5)]\n",
    "d = np.mean(np.asarray(qda_res), axis=0)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GchIyM_yCi6d"
   },
   "outputs": [],
   "source": [
    "lplda_res = [fold_k(X,y,k,G, lda_lp) for k in np.arange(5)]\n",
    "# print(lplda_res)\n",
    "d = np.mean(np.asarray(lplda_res), axis=0)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "z3PEFYQ5HGrd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20553795278576384"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lplda_res = [fold_k(X,y,k,G, lda_lp_original) for k in np.arange(5)]\n",
    "# print(lplda_res)\n",
    "d = np.mean(np.asarray(lplda_res), axis=0)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X,y = iris.data, iris.target.ravel() \n",
    "G = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "tradi_res = [fold_k(X,y,k,G, tradi_lda) for k in np.arange(5)]\n",
    "varlda_res = [fold_k(X,y,k,G, varLDA) for k in np.arange(5)]\n",
    "b = np.mean(np.asarray(tradi_res), axis=0)\n",
    "c = np.mean(np.asarray(varlda_res), axis=0)\n",
    "b,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014285714285714285"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qda_res = [fold_k(X,y,k,G, qda) for k in np.arange(5)]\n",
    "d = np.mean(np.asarray(qda_res), axis=0)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0288637194008038, 0.03652564102564103)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varSrhinklda_res = [fold_k(X,y,k,G, varShrinkLDA) for k in np.arange(5)]\n",
    "shrinklda_res = [fold_k(X,y,k,G, shrink_lda) for k in np.arange(5)]\n",
    "np.mean(np.asarray(varSrhinklda_res), axis=0), np.mean(np.asarray(shrinklda_res), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lplda_res = [fold_k(X,y,k,G, lda_lp) for k in np.arange(5)]\n",
    "# print(lplda_res)\n",
    "d = np.mean(np.asarray(lplda_res), axis=0)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02641931216931217"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lplda_res = [fold_k(X,y,k,G, lda_lp_original) for k in np.arange(5)]\n",
    "# print(lplda_res)\n",
    "d = np.mean(np.asarray(lplda_res), axis=0)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vp4dGoHxb6bD"
   },
   "source": [
    "\n",
    "\n",
    "# Wine better 3%, 0%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O_tnZuarb58d",
    "outputId": "5ed93d24-277f-4e97-bb9e-595f9261e9a3"
   },
   "outputs": [],
   "source": [
    "wine = datasets.load_wine()\n",
    "X,y = wine.data, wine.target.ravel() \n",
    "G = 3\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "tradi_res = [fold_k(X,y,k,G, tradi_lda) for k in np.arange(5)]\n",
    "varlda_res = [fold_k(X,y,k,G, varLDA) for k in np.arange(5)]\n",
    "b = np.mean(np.asarray(tradi_res), axis=0)\n",
    "c = np.mean(np.asarray(varlda_res), axis=0)\n",
    "b,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9dPyEibcGfrP",
    "outputId": "55509cc5-ede6-477a-a67b-570166d456d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017152961980548186"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qda_res = [fold_k(X,y,k,G, qda) for k in np.arange(5)]\n",
    "d = np.mean(np.asarray(qda_res), axis=0)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AvXMtbY0HnUA",
    "outputId": "c83a5e6e-0ed8-4a4f-829d-2e37e2d294b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.23140225787284613, 0.3018885448916409)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 5\n",
    "varSrhinklda_res = [fold_k(X,y,k,G, varShrinkLDA) for k in np.arange(K)]\n",
    "shrinklda_res = [fold_k(X,y,k,G, shrink_lda) for k in np.arange(K)]\n",
    "np.mean(np.asarray(varSrhinklda_res), axis=0), np.mean(np.asarray(shrinklda_res), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lplda_res = [fold_k(X,y,k,G, lda_lp) for k in np.arange(5)]\n",
    "# print(lplda_res)\n",
    "d = np.mean(np.asarray(lplda_res), axis=0)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06048245906004527"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lplda_res = [fold_k(X,y,k,G, lda_lp_original) for k in np.arange(5)]\n",
    "# print(lplda_res)\n",
    "d = np.mean(np.asarray(lplda_res), axis=0)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "UC-FDA.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
